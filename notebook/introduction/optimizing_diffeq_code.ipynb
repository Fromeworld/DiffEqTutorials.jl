{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will walk through some of the main tools for optimizing your code in order to efficiently solve DifferentialEquations.jl. User-side optimizations are important because, for sufficiently difficult problems, most of the time will be spent inside of your `f` function, the function you are trying to solve. \"Efficient\" integrators are those that reduce the required number of `f` calls to hit the error tolerance. The main ideas for optimizing your DiffEq code, or any Julia function, are the following:\n",
    "\n",
    "- Make it non-allocating\n",
    "- Use StaticArrays for small arrays\n",
    "- Use broadcast fusion\n",
    "- Make it type-stable\n",
    "- Reduce redundant calculations\n",
    "- Make use of BLAS calls\n",
    "- Optimize algorithm choice\n",
    "\n",
    "We'll discuss these strategies in the context of small and large systems. Let's start with small systems.\n",
    "\n",
    "## Optimizing Small Systems (<100 DEs)\n",
    "\n",
    "Let's take the classic Lorenz system from before. Let's start by naively writing the system in its out-of-place form:\n",
    "# Optimizing DiffEq Code\n",
    "### Chris Rackauckas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:03:20.078000+01:00",
     "start_time": "2019-03-14T23:03:18.180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lorenz (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lorenz(u,p,t)\n",
    " dx = 10.0*(u[2]-u[1])\n",
    " dy = u[1]*(28.0-u[3]) - u[2]\n",
    " dz = u[1]*u[2] - (8/3)*u[3]\n",
    " [dx,dy,dz]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `lorenz` returns an object, `[dx,dy,dz]`, which is created within the body of `lorenz`.\n",
    "\n",
    "This is a common code pattern from high-level languages like MATLAB, SciPy, or R's deSolve. However, the issue with this form is that it allocates a vector, `[dx,dy,dz]`, at each step. Let's benchmark the solution process with this choice of function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:04:09.959000+01:00",
     "start_time": "2019-03-14T23:03:52.122Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling BenchmarkTools [6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf]\n",
      "└ @ Base loading.jl:1186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  10.94 MiB\n",
       "  allocs estimate:  102469\n",
       "  --------------\n",
       "  minimum time:     3.455 ms (0.00% GC)\n",
       "  median time:      4.810 ms (0.00% GC)\n",
       "  mean time:        4.788 ms (12.08% GC)\n",
       "  maximum time:     56.229 ms (89.52% GC)\n",
       "  --------------\n",
       "  samples:          1043\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DifferentialEquations, BenchmarkTools\n",
    "u0 = [1.0;0.0;0.0]\n",
    "tspan = (0.0,100.0)\n",
    "prob = ODEProblem(lorenz,u0,tspan)\n",
    "@benchmark solve(prob,Tsit5())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BenchmarkTools package's `@benchmark` runs the code multiple times to get an accurate measurement. The minimum time is the time it takes when your OS and other background processes aren't getting in the way. Notice that in this case it takes about 5ms to solve and allocates around 11.11 MiB. However, if we were to use this inside of a real user code we'd see a lot of time spent doing garbage collection (GC) to clean up all of the arrays we made. Even if we turn off saving we have these allocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:04:35.610000+01:00",
     "start_time": "2019-03-14T23:04:24.476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  9.57 MiB\n",
       "  allocs estimate:  89577\n",
       "  --------------\n",
       "  minimum time:     2.993 ms (0.00% GC)\n",
       "  median time:      4.178 ms (0.00% GC)\n",
       "  mean time:        4.231 ms (10.06% GC)\n",
       "  maximum time:     55.648 ms (89.30% GC)\n",
       "  --------------\n",
       "  samples:          1180\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark solve(prob,Tsit5(),save_everystep=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of course is that arrays are created every time our derivative function is called. This function is called multiple times per step and is thus the main source of memory usage. To fix this, we can use the in-place form to ***make our code non-allocating***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:04:45.709000+01:00",
     "start_time": "2019-03-14T23:04:45.325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lorenz! (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lorenz!(du,u,p,t)\n",
    " du[1] = 10.0*(u[2]-u[1])\n",
    " du[2] = u[1]*(28.0-u[3]) - u[2]\n",
    " du[3] = u[1]*u[2] - (8/3)*u[3]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, instead of creating an array each time, we utilized the cache array `du`. When the inplace form is used, DifferentialEquations.jl takes a different internal route that minimizes the internal allocations as well. When we benchmark this function, we will see quite a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:05:05.273000+01:00",
     "start_time": "2019-03-14T23:04:52.735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.37 MiB\n",
       "  allocs estimate:  12964\n",
       "  --------------\n",
       "  minimum time:     719.300 μs (0.00% GC)\n",
       "  median time:      863.950 μs (0.00% GC)\n",
       "  mean time:        996.328 μs (7.60% GC)\n",
       "  maximum time:     52.938 ms (97.40% GC)\n",
       "  --------------\n",
       "  samples:          5004\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u0 = [1.0;0.0;0.0]\n",
    "tspan = (0.0,100.0)\n",
    "prob = ODEProblem(lorenz!,u0,tspan)\n",
    "@benchmark solve(prob,Tsit5())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:05:26.399000+01:00",
     "start_time": "2019-03-14T23:05:15.788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  6.86 KiB\n",
       "  allocs estimate:  92\n",
       "  --------------\n",
       "  minimum time:     388.800 μs (0.00% GC)\n",
       "  median time:      424.500 μs (0.00% GC)\n",
       "  mean time:        456.487 μs (0.16% GC)\n",
       "  maximum time:     3.320 ms (86.45% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark solve(prob,Tsit5(),save_everystep=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a 4x time difference just from that change! Notice there are still some allocations and this is due to the construction of the integration cache. But this doesn't scale with the problem size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:05:38.867000+01:00",
     "start_time": "2019-03-14T23:05:27.804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  6.86 KiB\n",
       "  allocs estimate:  92\n",
       "  --------------\n",
       "  minimum time:     1.997 ms (0.00% GC)\n",
       "  median time:      2.255 ms (0.00% GC)\n",
       "  mean time:        2.366 ms (0.00% GC)\n",
       "  maximum time:     4.923 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2108\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tspan = (0.0,500.0) # 5x longer than before\n",
    "prob = ODEProblem(lorenz!,u0,tspan)\n",
    "@benchmark solve(prob,Tsit5(),save_everystep=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since that's all just setup allocations.\n",
    "\n",
    "#### But if the system is small we can optimize even more.\n",
    "\n",
    "Allocations are only expensive if they are \"heap allocations\". For a more in-depth definition of heap allocations, [there are a lot of sources online](http://net-informations.com/faq/net/stack-heap.htm). But a good working definition is that heap allocations are variable-sized slabs of memory which have to be pointed to, and this pointer indirection costs time. Additionally, the heap has to be managed and the garbage controllers has to actively keep track of what's on the heap.\n",
    "\n",
    "However, there's an alternative to heap allocations, known as stack allocations. The stack is statically-sized (known at compile time) and thus its accesses are quick. Additionally, the exact block of memory is known in advance by the compiler, and thus re-using the memory is cheap. This means that allocating on the stack has essentially no cost!\n",
    "\n",
    "Arrays have to be heap allocated because their size (and thus the amount of memory they take up) is determined at runtime. But there are structures in Julia which are stack-allocated. `struct`s for example are stack-allocated \"value-type\"s. `Tuple`s are a stack-allocated collection. The most useful data structure for DiffEq though is the `StaticArray` from the package [StaticArrays.jl](https://github.com/JuliaArrays/StaticArrays.jl). These arrays have their length determined at compile-time. They are created using macros attached to normal array expressions, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:06:06.498000+01:00",
     "start_time": "2019-03-14T23:06:05.289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element SArray{Tuple{3},Float64,1,3}:\n",
       " 2.0\n",
       " 3.0\n",
       " 5.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using StaticArrays\n",
    "A = @SVector [2.0,3.0,5.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `3` after `SVector` gives the size of the `SVector`. It cannot be changed. Additionally, `SVector`s are immutable, so we have to create a new `SVector` to change values. But remember, we don't have to worry about allocations because this data structure is stack-allocated. `SArray`s have a lot of extra optimizations as well: they have fast matrix multiplication, fast QR factorizations, etc. which directly make use of the information about the size of the array. Thus, when possible they should be used.\n",
    "\n",
    "Unfortunately static arrays can only be used for sufficiently small arrays. After a certain size, they are forced to heap allocate after some instructions and their compile time balloons. Thus static arrays shouldn't be used if your system has more than 100 variables. Additionally, only the native Julia algorithms can fully utilize static arrays.\n",
    "\n",
    "Let's ***optimize `lorenz` using static arrays***. Note that in this case, we want to use the out-of-place allocating form, but this time we want to output a static array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:06:10.015000+01:00",
     "start_time": "2019-03-14T23:06:09.893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lorenz_static (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lorenz_static(u,p,t)\n",
    " dx = 10.0*(u[2]-u[1])\n",
    " dy = u[1]*(28.0-u[3]) - u[2]\n",
    " dz = u[1]*u[2] - (8/3)*u[3]\n",
    " @SVector [dx,dy,dz]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the solver internally use static arrays, we simply give it a static array as the initial condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:06:25.936000+01:00",
     "start_time": "2019-03-14T23:06:12.908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  472.02 KiB\n",
       "  allocs estimate:  2662\n",
       "  --------------\n",
       "  minimum time:     423.700 μs (0.00% GC)\n",
       "  median time:      475.600 μs (0.00% GC)\n",
       "  mean time:        519.208 μs (2.59% GC)\n",
       "  maximum time:     1.817 ms (48.73% GC)\n",
       "  --------------\n",
       "  samples:          9591\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u0 = @SVector [1.0,0.0,0.0]\n",
    "tspan = (0.0,100.0)\n",
    "prob = ODEProblem(lorenz_static,u0,tspan)\n",
    "@benchmark solve(prob,Tsit5())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:06:38.324000+01:00",
     "start_time": "2019-03-14T23:06:28.507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  6.16 KiB\n",
       "  allocs estimate:  73\n",
       "  --------------\n",
       "  minimum time:     340.901 μs (0.00% GC)\n",
       "  median time:      370.400 μs (0.00% GC)\n",
       "  mean time:        395.819 μs (0.13% GC)\n",
       "  maximum time:     2.881 ms (86.59% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark solve(prob,Tsit5(),save_everystep=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's pretty much all there is to it. With static arrays you don't have to worry about allocating, so use operations like `*` and don't worry about fusing operations (discussed in the next section). Do \"the vectorized code\" of R/MATLAB/Python and your code in this case will be fast, or directly use the numbers/values.\n",
    "\n",
    "#### Exercise 1\n",
    "\n",
    "Implement the out-of-place array, in-place array, and out-of-place static array forms for the [Henon-Heiles System](https://en.wikipedia.org/wiki/H%C3%A9non%E2%80%93Heiles_system) and time the results.\n",
    "\n",
    "## Optimizing Large Systems\n",
    "\n",
    "### Interlude: Managing Allocations with Broadcast Fusion\n",
    "\n",
    "When your system is sufficiently large, or you have to make use of a non-native Julia algorithm, you have to make use of `Array`s. In order to use arrays in the most efficient manner, you need to be careful about temporary allocations. Vectorized calculations naturally have plenty of temporary array allocations. This is because a vectorized calculation outputs a vector. Thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:06:55.845000+01:00",
     "start_time": "2019-03-14T23:06:44.617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.63 MiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     3.257 ms (0.00% GC)\n",
       "  median time:      4.102 ms (0.00% GC)\n",
       "  mean time:        4.647 ms (17.26% GC)\n",
       "  maximum time:     60.949 ms (92.17% GC)\n",
       "  --------------\n",
       "  samples:          1074\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(1000,1000); B = rand(1000,1000); C = rand(1000,1000)\n",
    "test(A,B,C) = A + B + C\n",
    "@benchmark test(A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That expression `A + B + C` creates 2 arrays. It first creates one for the output of `A + B`, then uses that result array to `+ C` to get the final result. 2 arrays! We don't want that! The first thing to do to fix this is to use broadcast fusion. [Broadcast fusion](https://julialang.org/blog/2017/01/moredots) puts expressions together. For example, instead of doing the `+` operations separately, if we were to add them all at the same time, then we would only have a single array that's created. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:07:12.807000+01:00",
     "start_time": "2019-03-14T23:07:01.790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.63 MiB\n",
       "  allocs estimate:  5\n",
       "  --------------\n",
       "  minimum time:     4.263 ms (0.00% GC)\n",
       "  median time:      5.274 ms (0.00% GC)\n",
       "  mean time:        5.760 ms (14.21% GC)\n",
       "  maximum time:     60.352 ms (91.60% GC)\n",
       "  --------------\n",
       "  samples:          867\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2(A,B,C) = map((a,b,c)->a+b+c,A,B,C)\n",
    "@benchmark test2(A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puts the whole expression into a single function call, and thus only one array is required to store output. This is the same as writing the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:07:25.046000+01:00",
     "start_time": "2019-03-14T23:07:13.987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.63 MiB\n",
       "  allocs estimate:  2\n",
       "  --------------\n",
       "  minimum time:     3.068 ms (0.00% GC)\n",
       "  median time:      4.069 ms (0.00% GC)\n",
       "  mean time:        4.573 ms (17.14% GC)\n",
       "  maximum time:     60.806 ms (93.12% GC)\n",
       "  --------------\n",
       "  samples:          1091\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test3(A,B,C)\n",
    "    D = similar(A)\n",
    "    @inbounds for i in eachindex(A)\n",
    "        D[i] = A[i] + B[i] + C[i]\n",
    "    end\n",
    "    D\n",
    "end\n",
    "@benchmark test3(A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, Julia's broadcast is syntactic sugar for this. If multiple expressions have a `.`, then it will put those vectorized operations together. Thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:07:36.174000+01:00",
     "start_time": "2019-03-14T23:07:16.280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.63 MiB\n",
       "  allocs estimate:  2\n",
       "  --------------\n",
       "  minimum time:     3.100 ms (0.00% GC)\n",
       "  median time:      4.090 ms (0.00% GC)\n",
       "  mean time:        4.611 ms (17.00% GC)\n",
       "  maximum time:     60.075 ms (91.42% GC)\n",
       "  --------------\n",
       "  samples:          1083\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4(A,B,C) = A .+ B .+ C\n",
    "@benchmark test4(A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is a version with only 1 array created (the output). Note that `.`s can be used with function calls as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:07:50.213000+01:00",
     "start_time": "2019-03-14T23:07:48.994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×1000 Array{Float64,2}:\n",
       " 1.03364    0.98507   1.27358    0.877     …  0.573536  1.23032   0.911319\n",
       " 1.63118    1.53896   0.71938    0.982407     1.18889   0.666447  0.456239\n",
       " 1.326      0.635384  1.00153    0.872837     0.57143   0.957094  0.644016\n",
       " 1.20394    0.252596  0.586836   0.706981     0.484221  1.16159   0.320898\n",
       " 0.602921   0.942712  0.245305   1.04536      0.811623  1.01748   1.49487 \n",
       " 0.967846   0.933214  0.425036   0.763434  …  0.339187  0.863011  0.697906\n",
       " 0.672935   0.702386  0.815461   1.4289       1.43948   1.23604   0.991722\n",
       " 0.57422    1.16769   0.553201   0.327915     0.303723  0.17508   1.62917 \n",
       " 0.16162    1.48327   0.394958   1.32529      0.73105   0.559688  0.996632\n",
       " 0.664391   0.808939  1.36914    0.981928     0.702237  0.539255  1.432   \n",
       " 0.811794   1.08456   0.632371   1.07589   …  1.45691   1.66896   0.456393\n",
       " 0.951618   0.533518  0.78531    1.27613      0.887392  0.883319  1.43496 \n",
       " 1.14518    1.27886   0.719942   0.939989     0.399901  0.768837  0.314349\n",
       " ⋮                                         ⋱                              \n",
       " 1.35936    1.06333   0.885049   1.31827      1.1435    0.501145  0.358912\n",
       " 1.30287    1.31587   1.1749     0.975842     1.61852   1.10175   0.68206 \n",
       " 0.749153   1.35504   1.4116     1.15027   …  1.20905   0.864016  1.1477  \n",
       " 1.27482    0.576958  1.17769    0.77052      0.532696  0.833744  1.28555 \n",
       " 1.04075    0.844666  0.360267   1.27131      0.679665  0.533756  1.4078  \n",
       " 0.674019   0.831317  1.5796     0.122812     0.585702  1.10292   1.46805 \n",
       " 0.921581   1.47563   1.16279    1.26375      0.535886  1.04286   0.698426\n",
       " 0.508372   1.27464   0.0699981  1.29666   …  1.59411   1.02171   1.14568 \n",
       " 0.0579072  0.884255  0.277504   0.957518     0.521798  1.38383   1.38164 \n",
       " 0.958096   1.00757   1.52481    1.49831      1.37391   0.829876  1.52642 \n",
       " 0.627583   1.14951   0.796797   1.43778      1.17557   0.490823  0.480095\n",
       " 0.234199   0.78984   1.28475    1.36424      1.11589   0.335778  0.113732"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin.(A) .+ sin.(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the `@.` macro applys a dot to every operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:08:08.929000+01:00",
     "start_time": "2019-03-14T23:07:57.980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.63 MiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     3.213 ms (0.00% GC)\n",
       "  median time:      4.115 ms (0.00% GC)\n",
       "  mean time:        4.570 ms (15.95% GC)\n",
       "  maximum time:     8.086 ms (38.82% GC)\n",
       "  --------------\n",
       "  samples:          1092\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test5(A,B,C) = @. A + B + C #only one array allocated\n",
    "@benchmark test5(A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these tools we can get rid of our intermediate array allocations for many vectorized function calls. But we are still allocating the output array. To get rid of that allocation, we can instead use mutation. Mutating broadcast is done via `.=`. For example, if we pre-allocate the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:08:10.530000+01:00",
     "start_time": "2019-03-14T23:08:10.504Z"
    }
   },
   "outputs": [],
   "source": [
    "D = zeros(1000,1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can keep re-using this cache for subsequent calculations. The mutating broadcasting form is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:08:23.090000+01:00",
     "start_time": "2019-03-14T23:08:12.259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     799.699 μs (0.00% GC)\n",
       "  median time:      902.050 μs (0.00% GC)\n",
       "  mean time:        962.816 μs (0.00% GC)\n",
       "  maximum time:     3.425 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5152\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test6!(D,A,B,C) = D .= A .+ B .+ C #only one array allocated\n",
    "@benchmark test6!(D,A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use `@.` before the `=`, then it will turn it into `.=`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:08:35.636000+01:00",
     "start_time": "2019-03-14T23:08:24.770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     798.400 μs (0.00% GC)\n",
       "  median time:      892.550 μs (0.00% GC)\n",
       "  mean time:        950.436 μs (0.00% GC)\n",
       "  maximum time:     2.693 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5218\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test7!(D,A,B,C) = @. D = A + B + C #only one array allocated\n",
    "@benchmark test7!(D,A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in this case, there is no \"output\", and instead the values inside of `D` are what are changed (like with the DiffEq inplace function). Many Julia functions have a mutating form which is denoted with a `!`. For example, the mutating form of the `map` is `map!`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:08:47.792000+01:00",
     "start_time": "2019-03-14T23:08:36.994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  32 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     1.049 ms (0.00% GC)\n",
       "  median time:      1.167 ms (0.00% GC)\n",
       "  mean time:        1.238 ms (0.00% GC)\n",
       "  maximum time:     3.015 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          4011\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test8!(D,A,B,C) = map!((a,b,c)->a+b+c,D,A,B,C)\n",
    "@benchmark test8!(D,A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some operations require using an alternate mutating form in order to be fast. For example, matrix multiplication via `*` allocates a temporary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:09:01.100000+01:00",
     "start_time": "2019-03-14T23:08:49.848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.63 MiB\n",
       "  allocs estimate:  2\n",
       "  --------------\n",
       "  minimum time:     12.283 ms (0.00% GC)\n",
       "  median time:      13.676 ms (0.00% GC)\n",
       "  mean time:        14.268 ms (5.67% GC)\n",
       "  maximum time:     20.365 ms (12.72% GC)\n",
       "  --------------\n",
       "  samples:          350\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark A*B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we can use the mutating form `mul!` into a cache array to avoid allocating the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:09:16.457000+01:00",
     "start_time": "2019-03-14T23:09:05.462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     11.668 ms (0.00% GC)\n",
       "  median time:      12.447 ms (0.00% GC)\n",
       "  mean time:        12.623 ms (0.00% GC)\n",
       "  maximum time:     16.679 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          396\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "@benchmark mul!(D,A,B) # same as D = A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For repeated calculations this reduced allocation can stop GC cycles and thus lead to more efficient code. Additionally, ***we can fuse together higher level linear algebra operations using BLAS***. The package [SugarBLAS.jl](https://github.com/lopezm94/SugarBLAS.jl) makes it easy to write higher level operations like `alpha*B*A + beta*C` as mutating BLAS calls.\n",
    "\n",
    "### Example Optimization: Gierer-Meinhardt Reaction-Diffusion PDE Discretization\n",
    "\n",
    "Let's optimize the solution of a Reaction-Diffusion PDE's discretization. In its discretized form, this is the ODE:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "du &= D_1 (A_y u + u A_x) + \\frac{au^2}{v} + \\bar{u} - \\alpha u\\\\\n",
    "dv &= D_2 (A_y v + v A_x) + a u^2 + \\beta v\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $u$, $v$, and $A$ are matrices. Here, we will use the simplified version where $A$ is the tridiagonal stencil $[1,-2,1]$, i.e. it's the 2D discretization of the LaPlacian. The native code would be something along the lines of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:09:22.220000+01:00",
     "start_time": "2019-03-14T23:09:21.167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mODEProblem\u001b[0m with uType \u001b[36mArray{Float64,3}\u001b[0m and tType \u001b[36mFloat64\u001b[0m. In-place: \u001b[36mtrue\u001b[0m\n",
       "timespan: (0.0, 0.1)\n",
       "u0: [11.0394 11.002 … 11.013 11.0926; 11.0837 11.0584 … 11.0908 11.0092; … ; 11.0918 11.0966 … 11.0582 11.0298; 11.0307 11.0959 … 11.0378 11.0558]\n",
       "\n",
       "[12.1 12.1 … 12.1 12.1; 12.1 12.1 … 12.1 12.1; … ; 12.1 12.1 … 12.1 12.1; 12.1 12.1 … 12.1 12.1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the constants\n",
    "p = (1.0,1.0,1.0,10.0,0.001,100.0) # a,α,ubar,β,D1,D2\n",
    "N = 100\n",
    "Ax = Array(Tridiagonal([1.0 for i in 1:N-1],[-2.0 for i in 1:N],[1.0 for i in 1:N-1]))\n",
    "Ay = copy(Ax)\n",
    "Ax[2,1] = 2.0\n",
    "Ax[end-1,end] = 2.0\n",
    "Ay[1,2] = 2.0\n",
    "Ay[end,end-1] = 2.0\n",
    "\n",
    "function basic_version!(dr,r,p,t)\n",
    "  a,α,ubar,β,D1,D2 = p\n",
    "  u = r[:,:,1]\n",
    "  v = r[:,:,2]\n",
    "  Du = D1*(Ay*u + u*Ax)\n",
    "  Dv = D2*(Ay*v + v*Ax)\n",
    "  dr[:,:,1] = Du .+ a.*u.*u./v .+ ubar .- α*u\n",
    "  dr[:,:,2] = Dv .+ a.*u.*u .- β*v\n",
    "end\n",
    "\n",
    "a,α,ubar,β,D1,D2 = p\n",
    "uss = (ubar+β)/α\n",
    "vss = (a/β)*uss^2\n",
    "r0 = zeros(100,100,2)\n",
    "r0[:,:,1] .= uss.+0.1.*rand.()\n",
    "r0[:,:,2] .= vss\n",
    "\n",
    "prob = ODEProblem(basic_version!,r0,(0.0,0.1),p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version we have encoded our initial condition to be a 3-dimensional array, with `u[:,:,1]` being the `A` part and `u[:,:,2]` being the `B` part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:09:39.346000+01:00",
     "start_time": "2019-03-14T23:09:24.931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  186.88 MiB\n",
       "  allocs estimate:  8589\n",
       "  --------------\n",
       "  minimum time:     80.334 ms (8.83% GC)\n",
       "  median time:      167.756 ms (48.87% GC)\n",
       "  mean time:        137.745 ms (37.82% GC)\n",
       "  maximum time:     192.902 ms (47.32% GC)\n",
       "  --------------\n",
       "  samples:          37\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark solve(prob,Tsit5())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this version isn't very efficient,\n",
    "\n",
    "#### We recommend writing the \"high-level\" code first, and iteratively optimizing it!\n",
    "\n",
    "The first thing that we can do is get rid of the slicing allocations. The operation `r[:,:,1]` creates a temporary array instead of a \"view\", i.e. a pointer to the already existing memory. To make it a view, add `@view`. Note that we have to be careful with views because they point to the same memory, and thus changing a view changes the original values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:09:54.726000+01:00",
     "start_time": "2019-03-14T23:09:53.867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = [0.22581, 0.809546, 0.344768, 0.640214]\n",
      "A = [0.22581, 2.0, 0.344768, 0.640214]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.2258101941951307\n",
       " 2.0               \n",
       " 0.3447681198957038\n",
       " 0.6402135416553185"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(4)\n",
    "@show A\n",
    "B = @view A[1:3]\n",
    "B[2] = 2\n",
    "@show A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that changing `B` changed `A`. This is something to be careful of, but at the same time we want to use this since we want to modify the output `dr`. Additionally, the last statement is a purely element-wise operation, and thus we can make use of broadcast fusion there. Let's rewrite `basic_version!` to ***avoid slicing allocations*** and to ***use broadcast fusion***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:10:16.166000+01:00",
     "start_time": "2019-03-14T23:10:02.314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  119.55 MiB\n",
       "  allocs estimate:  7119\n",
       "  --------------\n",
       "  minimum time:     69.464 ms (6.19% GC)\n",
       "  median time:      119.849 ms (35.84% GC)\n",
       "  mean time:        119.770 ms (37.59% GC)\n",
       "  maximum time:     175.505 ms (55.22% GC)\n",
       "  --------------\n",
       "  samples:          42\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gm2!(dr,r,p,t)\n",
    "  a,α,ubar,β,D1,D2 = p\n",
    "  u = @view r[:,:,1]\n",
    "  v = @view r[:,:,2]\n",
    "  du = @view dr[:,:,1]\n",
    "  dv = @view dr[:,:,2]\n",
    "  Du = D1*(Ay*u + u*Ax)\n",
    "  Dv = D2*(Ay*v + v*Ax)\n",
    "  @. du = Du + a.*u.*u./v + ubar - α*u\n",
    "  @. dv = Dv + a.*u.*u - β*v\n",
    "end\n",
    "prob = ODEProblem(gm2!,r0,(0.0,0.1),p)\n",
    "@benchmark solve(prob,Tsit5())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, most of the allocations are taking place in `Du = D1*(Ay*u + u*Ax)` since those operations are vectorized and not mutating. We should instead replace the matrix multiplications with `mul!`. When doing so, we will need to have cache variables to write into. This looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:10:35.659000+01:00",
     "start_time": "2019-03-14T23:10:20.986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  29.76 MiB\n",
       "  allocs estimate:  5355\n",
       "  --------------\n",
       "  minimum time:     54.087 ms (2.33% GC)\n",
       "  median time:      57.128 ms (2.28% GC)\n",
       "  mean time:        59.910 ms (5.30% GC)\n",
       "  maximum time:     142.458 ms (51.42% GC)\n",
       "  --------------\n",
       "  samples:          84\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ayu = zeros(N,N)\n",
    "uAx = zeros(N,N)\n",
    "Du = zeros(N,N)\n",
    "Ayv = zeros(N,N)\n",
    "vAx = zeros(N,N)\n",
    "Dv = zeros(N,N)\n",
    "function gm3!(dr,r,p,t)\n",
    "  a,α,ubar,β,D1,D2 = p\n",
    "  u = @view r[:,:,1]\n",
    "  v = @view r[:,:,2]\n",
    "  du = @view dr[:,:,1]\n",
    "  dv = @view dr[:,:,2]\n",
    "  mul!(Ayu,Ay,u)\n",
    "  mul!(uAx,u,Ax)\n",
    "  mul!(Ayv,Ay,v)\n",
    "  mul!(vAx,v,Ax)\n",
    "  @. Du = D1*(Ayu + uAx)\n",
    "  @. Dv = D2*(Ayv + vAx)\n",
    "  @. du = Du + a*u*u./v + ubar - α*u\n",
    "  @. dv = Dv + a*u*u - β*v\n",
    "end\n",
    "prob = ODEProblem(gm3!,r0,(0.0,0.1),p)\n",
    "@benchmark solve(prob,Tsit5())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But our temporary variables are global variables. We need to either declare the caches as `const` or localize them. We can localize them by adding them to the parameters, `p`. It's easier for the compiler to reason about local variables than global variables. ***Localizing variables helps to ensure type stability***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:10:51.542000+01:00",
     "start_time": "2019-03-14T23:10:37.259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  29.66 MiB\n",
       "  allocs estimate:  1090\n",
       "  --------------\n",
       "  minimum time:     46.933 ms (2.46% GC)\n",
       "  median time:      49.269 ms (2.41% GC)\n",
       "  mean time:        51.746 ms (5.35% GC)\n",
       "  maximum time:     137.551 ms (57.03% GC)\n",
       "  --------------\n",
       "  samples:          97\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (1.0,1.0,1.0,10.0,0.001,100.0,Ayu,uAx,Du,Ayv,vAx,Dv) # a,α,ubar,β,D1,D2\n",
    "function gm4!(dr,r,p,t)\n",
    "  a,α,ubar,β,D1,D2,Ayu,uAx,Du,Ayv,vAx,Dv = p\n",
    "  u = @view r[:,:,1]\n",
    "  v = @view r[:,:,2]\n",
    "  du = @view dr[:,:,1]\n",
    "  dv = @view dr[:,:,2]\n",
    "  mul!(Ayu,Ay,u)\n",
    "  mul!(uAx,u,Ax)\n",
    "  mul!(Ayv,Ay,v)\n",
    "  mul!(vAx,v,Ax)\n",
    "  @. Du = D1*(Ayu + uAx)\n",
    "  @. Dv = D2*(Ayv + vAx)\n",
    "  @. du = Du + a*u*u./v + ubar - α*u\n",
    "  @. dv = Dv + a*u*u - β*v\n",
    "end\n",
    "prob = ODEProblem(gm4!,r0,(0.0,0.1),p)\n",
    "@benchmark solve(prob,Tsit5())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could then use the BLAS `gemmv` to optimize the matrix multiplications some more, but instead let's devectorize the stencil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:12:29.945000+01:00",
     "start_time": "2019-03-14T23:12:18.239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  29.63 MiB\n",
       "  allocs estimate:  505\n",
       "  --------------\n",
       "  minimum time:     7.409 ms (8.40% GC)\n",
       "  median time:      8.683 ms (8.87% GC)\n",
       "  mean time:        9.342 ms (12.98% GC)\n",
       "  maximum time:     91.148 ms (78.92% GC)\n",
       "  --------------\n",
       "  samples:          535\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (1.0,1.0,1.0,10.0,0.001,100.0,N)\n",
    "function fast_gm!(du,u,p,t)\n",
    "  a,α,ubar,β,D1,D2,N = p\n",
    "\n",
    "  @inbounds for j in 2:N-1, i in 2:N-1\n",
    "    du[i,j,1] = D1*(u[i-1,j,1] + u[i+1,j,1] + u[i,j+1,1] + u[i,j-1,1] - 4u[i,j,1]) +\n",
    "              a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]\n",
    "  end\n",
    "\n",
    "  @inbounds for j in 2:N-1, i in 2:N-1\n",
    "    du[i,j,2] = D2*(u[i-1,j,2] + u[i+1,j,2] + u[i,j+1,2] + u[i,j-1,2] - 4u[i,j,2]) +\n",
    "            a*u[i,j,1]^2 - β*u[i,j,2]\n",
    "  end\n",
    "\n",
    "  @inbounds for j in 2:N-1\n",
    "    i = 1\n",
    "    du[1,j,1] = D1*(2u[i+1,j,1] + u[i,j+1,1] + u[i,j-1,1] - 4u[i,j,1]) +\n",
    "            a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]\n",
    "  end\n",
    "  @inbounds for j in 2:N-1\n",
    "    i = 1\n",
    "    du[1,j,2] = D2*(2u[i+1,j,2] + u[i,j+1,2] + u[i,j-1,2] - 4u[i,j,2]) +\n",
    "            a*u[i,j,1]^2 - β*u[i,j,2]\n",
    "  end\n",
    "  @inbounds for j in 2:N-1\n",
    "    i = N\n",
    "    du[end,j,1] = D1*(2u[i-1,j,1] + u[i,j+1,1] + u[i,j-1,1] - 4u[i,j,1]) +\n",
    "           a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]\n",
    "  end\n",
    "  @inbounds for j in 2:N-1\n",
    "    i = N\n",
    "    du[end,j,2] = D2*(2u[i-1,j,2] + u[i,j+1,2] + u[i,j-1,2] - 4u[i,j,2]) +\n",
    "           a*u[i,j,1]^2 - β*u[i,j,2]\n",
    "  end\n",
    "\n",
    "  @inbounds for i in 2:N-1\n",
    "    j = 1\n",
    "    du[i,1,1] = D1*(u[i-1,j,1] + u[i+1,j,1] + 2u[i,j+1,1] - 4u[i,j,1]) +\n",
    "              a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]\n",
    "  end\n",
    "  @inbounds for i in 2:N-1\n",
    "    j = 1\n",
    "    du[i,1,2] = D2*(u[i-1,j,2] + u[i+1,j,2] + 2u[i,j+1,2] - 4u[i,j,2]) +\n",
    "              a*u[i,j,1]^2 - β*u[i,j,2]\n",
    "  end\n",
    "  @inbounds for i in 2:N-1\n",
    "    j = N\n",
    "    du[i,end,1] = D1*(u[i-1,j,1] + u[i+1,j,1] + 2u[i,j-1,1] - 4u[i,j,1]) +\n",
    "             a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]\n",
    "  end\n",
    "  @inbounds for i in 2:N-1\n",
    "    j = N\n",
    "    du[i,end,2] = D2*(u[i-1,j,2] + u[i+1,j,2] + 2u[i,j-1,2] - 4u[i,j,2]) +\n",
    "             a*u[i,j,1]^2 - β*u[i,j,2]\n",
    "  end\n",
    "\n",
    "  @inbounds begin\n",
    "    i = 1; j = 1\n",
    "    du[1,1,1] = D1*(2u[i+1,j,1] + 2u[i,j+1,1] - 4u[i,j,1]) +\n",
    "              a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]\n",
    "    du[1,1,2] = D2*(2u[i+1,j,2] + 2u[i,j+1,2] - 4u[i,j,2]) +\n",
    "              a*u[i,j,1]^2 - β*u[i,j,2]\n",
    "\n",
    "    i = 1; j = N\n",
    "    du[1,N,1] = D1*(2u[i+1,j,1] + 2u[i,j-1,1] - 4u[i,j,1]) +\n",
    "             a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]\n",
    "    du[1,N,2] = D2*(2u[i+1,j,2] + 2u[i,j-1,2] - 4u[i,j,2]) +\n",
    "             a*u[i,j,1]^2 - β*u[i,j,2]\n",
    "\n",
    "    i = N; j = 1\n",
    "    du[N,1,1] = D1*(2u[i-1,j,1] + 2u[i,j+1,1] - 4u[i,j,1]) +\n",
    "             a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]\n",
    "    du[N,1,2] = D2*(2u[i-1,j,2] + 2u[i,j+1,2] - 4u[i,j,2]) +\n",
    "             a*u[i,j,1]^2 - β*u[i,j,2]\n",
    "\n",
    "    i = N; j = N\n",
    "    du[end,end,1] = D1*(2u[i-1,j,1] + 2u[i,j-1,1] - 4u[i,j,1]) +\n",
    "             a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]\n",
    "    du[end,end,2] = D2*(2u[i-1,j,2] + 2u[i,j-1,2] - 4u[i,j,2]) +\n",
    "             a*u[i,j,1]^2 - β*u[i,j,2]\n",
    "   end\n",
    "end\n",
    "prob = ODEProblem(fast_gm!,r0,(0.0,0.1),p)\n",
    "@benchmark solve(prob,Tsit5())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can do other things like multithread the main loops, but these optimizations get the last 2x-3x out. The main optimizations which apply everywhere are the ones we just performed (though the last one only works if your matrix is a stencil. This is known as a matrix-free implementation of the PDE discretization).\n",
    "\n",
    "This gets us to about 8x faster than our original MATLAB/SciPy/R vectorized style code!\n",
    "\n",
    "The last thing to do is then ***optimize our algorithm choice***. We have been using `Tsit5()` as our test algorithm, but in reality this problem is a stiff PDE discretization and thus one recommendation is to use `CVODE_BDF()`. However, instead of using the default dense Jacobian, we should make use of the sparse Jacobian afforded by the problem. The Jacobian is the matrix $\\frac{df_i}{dr_j}$, where $r$ is read by the linear index (i.e. down columns). But since the $u$ variables depend on the $v$, the band size here is large, and thus this will not do well with a Banded Jacobian solver. Instead, we utilize sparse Jacobian algorithms. `CVODE_BDF` allows us to use a sparse Newton-Krylov solver by setting `linear_solver = :GMRES` (see [the solver documentation](http://docs.juliadiffeq.org/latest/solvers/ode_solve.html#Sundials.jl-1), and thus we can solve this problem efficiently. Let's see how this scales as we increase the integration time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:13:42.432000+01:00",
     "start_time": "2019-03-14T23:13:11.665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.76 GiB\n",
       "  allocs estimate:  41689\n",
       "  --------------\n",
       "  minimum time:     2.255 s (13.38% GC)\n",
       "  median time:      2.399 s (19.28% GC)\n",
       "  mean time:        2.826 s (30.95% GC)\n",
       "  maximum time:     3.823 s (48.64% GC)\n",
       "  --------------\n",
       "  samples:          3\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = ODEProblem(fast_gm!,r0,(0.0,10.0),p)\n",
    "@benchmark solve(prob,Tsit5())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:14:27.885000+01:00",
     "start_time": "2019-03-14T23:14:09.715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  306.28 MiB\n",
       "  allocs estimate:  87141\n",
       "  --------------\n",
       "  minimum time:     1.819 s (0.00% GC)\n",
       "  median time:      1.831 s (4.41% GC)\n",
       "  mean time:        1.889 s (4.83% GC)\n",
       "  maximum time:     2.018 s (9.57% GC)\n",
       "  --------------\n",
       "  samples:          3\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Sundials\n",
    "@benchmark solve(prob,CVODE_BDF(linear_solver=:GMRES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:14:06.921000+01:00",
     "start_time": "2019-03-14T23:13:14.740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.91 MiB\n",
       "  allocs estimate:  113\n",
       "  --------------\n",
       "  minimum time:     5.422 s (0.00% GC)\n",
       "  median time:      5.422 s (0.00% GC)\n",
       "  mean time:        5.422 s (0.00% GC)\n",
       "  maximum time:     5.422 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          1\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = ODEProblem(fast_gm!,r0,(0.0,100.0),p)\n",
    "# Will go out of memory if we don't turn off `save_everystep`!\n",
    "@benchmark solve(prob,Tsit5(),save_everystep=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:14:52.303000+01:00",
     "start_time": "2019-03-14T23:14:36.308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  306.28 MiB\n",
       "  allocs estimate:  87141\n",
       "  --------------\n",
       "  minimum time:     1.849 s (4.01% GC)\n",
       "  median time:      1.871 s (3.96% GC)\n",
       "  mean time:        1.893 s (4.25% GC)\n",
       "  maximum time:     1.959 s (8.54% GC)\n",
       "  --------------\n",
       "  samples:          3\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark solve(prob,CVODE_BDF(linear_solver=:GMRES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the allocation growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:15:09.081000+01:00",
     "start_time": "2019-03-14T23:14:54.412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  4.07 MiB\n",
       "  allocs estimate:  77881\n",
       "  --------------\n",
       "  minimum time:     1.646 s (0.00% GC)\n",
       "  median time:      1.694 s (0.00% GC)\n",
       "  mean time:        1.705 s (0.00% GC)\n",
       "  maximum time:     1.774 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          3\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark solve(prob,CVODE_BDF(linear_solver=:GMRES),save_everystep=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T00:15:30.279000+01:00",
     "start_time": "2019-03-14T23:15:10.403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  5.31 MiB\n",
       "  allocs estimate:  108359\n",
       "  --------------\n",
       "  minimum time:     2.306 s (0.00% GC)\n",
       "  median time:      2.337 s (0.00% GC)\n",
       "  mean time:        2.340 s (0.00% GC)\n",
       "  maximum time:     2.375 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          3\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = ODEProblem(fast_gm!,r0,(0.0,500.0),p)\n",
    "@benchmark solve(prob,CVODE_BDF(linear_solver=:GMRES),save_everystep=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we've elimated almost all allocations, allowing the code to grow without hitting garbage collection and slowing down.\n",
    "\n",
    "Why is `CVODE_BDF` doing well? What's happening is that, because the problem is stiff, the number of steps required by the explicit Runge-Kutta method grows rapidly, whereas `CVODE_BDF` is taking large steps. Additionally, the `GMRES` linear solver form is quite an efficient way to solve the implicit system in this case. This is problem-dependent, and in many cases using a Krylov method effectively requires a preconditioner, so you need to play around with testing other algorithms and linear solvers to find out what works best with your problem.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Julia gives you the tools to optimize the solver \"all the way\", but you need to make use of it. The main thing to avoid is temporary allocations. For small systems, this is effectively done via static arrays. For large systems, this is done via in-place operations and cache arrays. Either way, the resulting solution can be immensely sped up over vectorized formulations by using these principles."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
